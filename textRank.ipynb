{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sumy \n",
    "from sumy.summarizers.text_rank import TextRankSummarizer \n",
    "from sumy.summarizers.lsa import LsaSummarizer \n",
    "from sumy.parsers.plaintext import PlaintextParser \n",
    "from sumy.nlp.tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import wrap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Using Text-Rank Summarizations for Normal Scripts </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1680\n",
      "Input: \n",
      "NLP (Natural Language Processing) is the field of artificial intelligence that studies the interactions between computers and human languages, in particular how to program computers to process and analyze large amounts of natural language data. The hardest NLP tasks are the ones where the output isn’t a single label or value (like Classification and Regression), but a full new text (like Translation, Summarization and Conversation). Text summarization is the problem of reducing the number of sentences and words of a document without changing its meaning. There are different techniques to extract information from raw text data and use it for a summarization model, overall they can be categorized as Extractive and Abstractive. Extractive methods select the most important sentences within a text (without necessarily understanding the meaning), therefore the result summary is just a subset of the full text. On the contrary, Abstractive models use advanced NLP (i.e. word embeddings) to understand the semantics of the text and generate a meaningful summary. Consequently, Abstractive techniques are much harder to train from scratch as they need a lot of parameters and data. This tutorial compares the old school approach of TextRank (Extractive), the popular encoder-decoder neural network Seq2Seq (Abstractive), and the state-of-the-art Attention-based Transformers (Abstractive) that have completely revolutionized the NLP landscape. I will present some useful Python code that can be easily applied in other similar cases (just copy, paste, run) and walk through every line of code with comments so that you can replicate this example (link to the full code below).\n"
     ]
    }
   ],
   "source": [
    "result = \"NLP (Natural Language Processing) is the field of artificial intelligence that studies the interactions between computers and human languages, in particular how to program computers to process and analyze large amounts of natural language data. The hardest NLP tasks are the ones where the output isn’t a single label or value (like Classification and Regression), but a full new text (like Translation, Summarization and Conversation). Text summarization is the problem of reducing the number of sentences and words of a document without changing its meaning. There are different techniques to extract information from raw text data and use it for a summarization model, overall they can be categorized as Extractive and Abstractive. Extractive methods select the most important sentences within a text (without necessarily understanding the meaning), therefore the result summary is just a subset of the full text. On the contrary, Abstractive models use advanced NLP (i.e. word embeddings) to understand the semantics of the text and generate a meaningful summary. Consequently, Abstractive techniques are much harder to train from scratch as they need a lot of parameters and data. This tutorial compares the old school approach of TextRank (Extractive), the popular encoder-decoder neural network Seq2Seq (Abstractive), and the state-of-the-art Attention-based Transformers (Abstractive) that have completely revolutionized the NLP landscape. I will present some useful Python code that can be easily applied in other similar cases (just copy, paste, run) and walk through every line of code with comments so that you can replicate this example (link to the full code below).\"\n",
    "print(len(result))\n",
    "print(\"Input: \")\n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer1 = TextRankSummarizer() \n",
    "parser1 = PlaintextParser.from_string(\n",
    "    result,\n",
    "    Tokenizer(\"english\")\n",
    ")\n",
    "summary = summarizer1(parser1.document, sentences_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<Sentence: NLP (Natural Language Processing) is the field of artificial intelligence that studies the interactions between computers and human languages, in particular how to program computers to process and analyze large amounts of natural language data.>, <Sentence: The hardest NLP tasks are the ones where the output isn’t a single label or value (like Classification and Regression), but a full new text (like Translation, Summarization and Conversation).>, <Sentence: Extractive methods select the most important sentences within a text (without necessarily understanding the meaning), therefore the result summary is just a subset of the full text.>, <Sentence: On the contrary, Abstractive models use advanced NLP (i.e. word embeddings) to understand the semantics of the text and generate a meaningful summary.>, <Sentence: This tutorial compares the old school approach of TextRank (Extractive), the popular encoder-decoder neural network Seq2Seq (Abstractive), and the state-of-the-art Attention-based Transformers (Abstractive) that have completely revolutionized the NLP landscape.>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\n",
    "for s in summary: \n",
    "    list1 = wrap(str(s))\n",
    "    str1 = ''.join(str(e) for e in list1)\n",
    "    a += str1 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015\n",
      "Final Summary:\n",
      "NLP (Natural Language Processing) is the field of artificialintelligence that studies the interactions between computers and humanlanguages, in particular how to program computers to process andanalyze large amounts of natural language data.The hardest NLP tasks are the ones where the output isn’t a singlelabel or value (like Classification and Regression), but a full newtext (like Translation, Summarization and Conversation).Extractive methods select the most important sentences within a text(without necessarily understanding the meaning), therefore the resultsummary is just a subset of the full text.On the contrary, Abstractive models use advanced NLP (i.e. wordembeddings) to understand the semantics of the text and generate ameaningful summary.This tutorial compares the old school approach of TextRank(Extractive), the popular encoder-decoder neural network Seq2Seq(Abstractive), and the state-of-the-art Attention-based Transformers(Abstractive) that have completely revolutionized the NLP landscape.\n"
     ]
    }
   ],
   "source": [
    "print(len(a))\n",
    "print(\"Final Summary:\")\n",
    "print(a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> YouTube Panel Discussion Summarization </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_video = \"https://www.youtube.com/watch?v=jWLwnD-GILM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = youtube_video.split(\"=\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/jWLwnD-GILM\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x29d33b9f6d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59769\n"
     ]
    }
   ],
   "source": [
    "transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "result = \"\"\n",
    "for i in transcript:\n",
    "  result += ' ' + i[\"text\"]\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " our next session will be panel and on the same topic of the impact on society I would like to introduce our panel moderator who will then introduce the members of the panel James mineka is a senior partner at McKinsey and he's the chair and director of the McKinsey Global Institute the company's research arm he is written and spoken extensively about AI and robotics and serves on a number of academic advisory boards including the Oxford internet Institute and the MIT initiative for the digital \n"
     ]
    }
   ],
   "source": [
    "print(result[0:500])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Need to Use Stop Punctuations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = int(len(result)/500)\n",
    "summarized_text = []\n",
    "for i in range(0, num_iters + 1):\n",
    "  start = 0\n",
    "  start = i * 2000\n",
    "  end = (i + 1) * 2000\n",
    " # print(\"input text \\n\" + result[start:end])\n",
    "  out = result[start:end]\n",
    " \n",
    "  summarized_text.append(out)\n",
    "\n",
    "#print(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(len(summarized_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result = \"\" \n",
    "for i in summarized_text:\n",
    "    new_result += i \n",
    "    new_result += \". \"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60009\n"
     ]
    }
   ],
   "source": [
    "print(len(new_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer1 = TextRankSummarizer() \n",
    "parser1 = PlaintextParser.from_string(\n",
    "    new_result,\n",
    "    Tokenizer(\"english\")\n",
    ")\n",
    "summary = summarizer1(parser1.document, sentences_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary = \"\"\n",
    "for i in summary:\n",
    "    a = wrap(str(i))\n",
    "    for i in a:\n",
    "        final_summary += i + ' '\n",
    "        \n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12011\n"
     ]
    }
   ],
   "source": [
    "print(len(final_summary)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " our next session will be panel and on the same topic of the impact on society I would like to introduce our panel moderator who will then introduce the members of the panel James mineka is a senior partner at McKinsey and he's the chair and director of the McKinsey Global Institute the company's research arm he is written and spoken extensively about AI and robotics and serves on a number of academic advisory boards including the Oxford internet Institute and the MIT initiative for the digital economy and the humans Stanford human-centered AI Institute James the floor is yours [Applause] well it's hard to talk about the human centered AI Institute or H AI without talking about the impacts on humans and on society so we have an amazing panel to do just that and I'm thrilled to be able to introduce them as they come up Susan Joanna come up Susan Athey is a professor of the economics of technology here at Stanford shows previously please take a seat she was previously the chief economist of Microsoft and actually works with a lot of technology companies we also have Kate Crawford Kate is a writer and researcher and as a professor at NYU she is the founder of AI now we'll talk a little bit about what that is but Kate is actually spent a lot of time thinking about these large-scale data systems sis's system challenges as well as the impact of machine learning and AI so glad to have Kate here we also have Tristan Harris Tristan is a former Googler but more recently he was the is the founder of the Center for Humane Technology and in fact many people have often described Tristan it's kind of the conscience of Silicon Valley and I'm sure we'll hear some of that and then finally we've got Aaron Olson eric is a professor at MIT at the Sloan Sloan School he's also the founder of the MIT initiative on economy it's actually currently spending a year on sabbatical here at Stanford most of you may know of Eric's book the second Machine Age we've talked a lot about the impacts of these things so we're going to cover some territory here no surprise we'll probably touch on issues around the impact on work we'll probably talk about the impact of AI on society justice equity kinds of concerns but we're also ultimately I think try to get to this questions about so who's responsible for making sure all this kind of gets to good good outcomes so what I've asked each of the panelists to do is to spend a couple minutes just giving at least they they're kind of the key things on their minds when they think about ai's impact on society let's start with you Eric well what's on your mind is you think about the impact in society well well this is about my mind for a long time as you mentioned since I've been working on that book with with co-author with Andy McAfee by the way I've been amazed by the technological progress we've heard so much about it this morning and just around in Silicon Valley a radius around here you see a lot of it being invented but at the same time also some of the challenges in the economic aspects of that and one of the things that that that led us to work on this research is that there's no economic law that everyone benefits and a lot of people were left behind and that was a little bit of a puzzle when I first looked at it because clear the technologies are inspiring but they're also these challenges that's it I don't want to bury the lead I do think that the first order effect is tremendous growth in the economic pie better health ability to solve so many of our societal program problems if we handle this right the next 10 years the next 20 years should be could be the best that couple of decades that humanity has ever seen our ability to do the sort of things that that Bill Gates and many other people were talking about in healthcare grow the economy and individual businesses have been benefitting tremendously there whether they're unicorns or the trillion dollar businesses or a lot of startups and some of the things that Feifei was talking about with those people out of high school but on the challengers side you know the fact that there's no economic law that everyone's benefit means that we need to be proactive about thinking about how we make this shared prosperity it's possible for some people to be left behind is it possible for a majority of people to be left behind I saw mark Duggan's slide there showing that median income roughly stagnated for 20 years in it and that's not something that happened in in previous decades and something we need to work harder on and the the the the challenge isn't so much massive job loss it's more a matter of poor quality jobs and uneven distribution the technology we're very far from artificial general intelligence that can do everything but the technology can do certain tasks extremely well and if you happen to have a job that mainly does those tasks you need to think about other things to do and managers entrepreneurs need to invent new ways of recombining skills and technology to create value the problem is that human skills human institutions business processes change much more slowly than technology does and so we're not keeping up on that front and that's why this this human centered AI initiative is so important is to help us work on the other side of the H AI challenge which is how can we adapt our economics or laws or societies otherwise we're gonna be facing more and more of the unintended consequences and seeing my fellow panelists here I'm sure we're going to get into algorithmic bias fake news privacy many of the other challenges that come as side effects of this technology and need to be handled square on ultimately if we don't address them explicitly then I think other people are going to there's there will be a growing tech backlash and so this is it not only an opportunity to do the right thing but also a necessity if we want to keep the technology moving forward well I'm particularly struck by your comment about there's no economic law that guarantees the outcomes and the that every benefits I'd love to come back to that at some point is too so what do we do about yes yeah that's that's the key question but Susan you've been thinking about some of these same issues too what's in your mind when you think about impact in society I agree with Eric that we we generally we were going to be able to make sort of more outputs with less inputs and that can potentially be good but the actual process of translating that into well being for all is much more challenging and so one thing that we need to be doing more and better now is to understand why are some people doing badly what are the forces that are are leading to this stagnation those questions still have not been completely unpacked despite a fair bit of empirical research but as we get more and better data and and are really better able to to measure at a finer level what's going on where where exactly have have jobs been been disappearing and why have people not been able to share in this overall growth those will help us identify the problems and I think that even though you know overall the tide may increase we've seen a lot of economic research that shows that if the things start going badly in a particular geography or location they can also spiral down you know people lose their jobs they go less to the hairdresser less to the restaurant and and they have less business and so on so you can certainly have concentrated especially geographically concentrated harm and we just have not done a very good job about figuring out how to fix that and how to smooth those kinds of transitions and that I think takes me to the second thing that I'm thinking about from a positive perspective AI has this great feature it's a general-purpose technology so a lot of the commercial incentives have led to huge advances in R&D in the private sector and we've also seen this great investment within universities and that R&D can be repurposed to solve social problems not that it's going to solve everything but the thing about digitally delivered services is that they have a very low marginal cost of delivery and so if we can actually figure out something that works we can deliver it at scale and so one thing that I'm really excited about is trying to develop the a body of research that can help social impact firms find it easier to get started collaborations between universities and nonprofits or governments to really help bring these services to the people who need them and the nice thing about digital services also is this this in AI systems generally is this culture of incremental innovation so generally a tech product is not good when it first launches instead you make it better and better and better you learn you adapt the one-size-fits-all isn't great but once it adapts to the person and really understands them it can actually really become effective and so I think there's a whole set of social problems where the conventional wisdom is that we don't have a solution but we just haven't tried this next set of technologies and so the university we have a whole university full of engineers and students of all disciplines who who would love to and as part of their education actually apprentice in in solving social problems and doing something impactful instead of just going to target ads in their internship and so I think we have a great opportunity to harness and leverage that huge desire of people to learn and of researchers to study to and direct those towards the problems that might be caused by AI and and generally automation into this digitization and then the the third point and I hope we'll come back to this in the discussion further but is when I spent a lot of time with tech companies and you know we can talk a lot about their perverse incentives and how profits might lead them to do things that can that aren't good for consumers or society but there's actually a lot of cases where the firm's really are mission driven and it's actually just hard it's hard because they're inventing the science they're inventing the business processes they're inventing the AI they're trying to do good but it they just weren't trained to anticipate all of the the consequences and so you know it's it's really incumbent upon us and this is really a core mission of high is to you know help provide that leadership one one company by themselves especially small companies couldn't possibly be expected to have the expertise to anticipate you know all the different things that their technologies all the consequences that could follow from their technologies and so by convening industry and government and academia I think there's the possibility to really get all the people in the room to start asking the right questions but that's gonna be an ongoing research process it's not like I could lay out now and say here are the rules and if you just do this you're AI will be good no instead the technology is going to progress and the policy research is going to have to progress right alongside it in an ongoing way so it's really a process rather than a single final goal and I know we're going to come back to these work impacts well that's clearly a big topic of most people's minds but is the two resident economists on our panel Susan and Eric are you optimistic about the impact on economic growth and productivity yes in time I think that one of the disappointments has been that actually proactivity has been pretty dismal in the past few years and that's actually been a little bit of a surprise and disappointment to me in thinking more about it and it really gets some of the things we're doing here at high which is that the technologies have been invented if you look at their capabilities you have to be incredibly optimistic this is one of the great general purpose technology is comparable to the steam engine or electricity but if you look back those technologies didn't instantly boost growth they took decades because new kinds of factories had to be invented new work rules whole new institutions had to be invented and that's what we need to do now as well and sadly that takes a lot longer than then sometimes inventing the technologies they're Greeson you just to add to that I think you know it can be very confusing it too to follow this space because on the one hand you see the a is you know playing go and you know the robots climbing the walls and doing backflips and so you sort of feel like it's like all solved but then when you look at the even the very most advanced tech firms and and the most advanced practical implementations they're still actually relatively primitive they're using very simple AI and you know there are some amazing successes but across the board even like personalization and recommendations or are still sort of so-so and those have been the ones that have gotten in some sense the most commercial incentive to improve so I think part of the thing is that we are just very early it takes a lot of time and one reason it takes a lot of time is that you have to actually figure out how to measure success if you're gonna climb up a mountain you know you need to have a good signal of which way to go and that's one reason that it actually takes a long time this isn't a breakthrough in the lab that just immediately is applicable everywhere the part about putting it in a practice is interdisciplinary and our discipline with an affirm and interdisciplinary within science but we're working on it okay Kate you've been thinking a lot about these many of these issues related to equity and justice and well first of all tell everybody what yeah now is by the way so the be delighted to thank you James so I mean I've essentially been researching the social implications of machine learning and artificial intelligence and large-scale data for well over a decade now and about three years ago with Meredith Whittaker who's also here today and we decided to found basically the world's first Institute based to the university dedicated to the social implications of AI really because we looked around and we realized that all of the other AI Institute's had really a strong focus just upon the technical on algorithms in code and it was clear to us that this was an incredibly important issue which is also why we welcome hi here at Stanford as a sister Institute on the west coast but certainly in in their creation of they are now Institute I've got really interested in kind of these sort of core issues around how do we start talking about AI and power who has it who doesn't have it where is it getting concentrated and who's experiencing the downsides of these systems we can't really talk about AI without talking about power it's like talking about nuclear and not talking about weapons you have to put power at the center of the analysis of how these tools are actually going to affect social institutions so in terms you know to answer your question about the research that I've been excited and working on the first one is really why is the true cost of an AI system so often we tend to think about AI systems as quite abstract as doing a set of optimizations and predictions but actually if you really start looking at what is required from a resource perspective the GPUs at the sort of natural mineral resources and also at the forms of labor that are required right through the chain right through to the Amazon Terk workers who are often used to train these systems you see something very different you see a profoundly resource intensive set of planetary networks and again as as many speakers have said today there are really only very few companies who can do AI at scale so they really are Planetary in that sense so what we did recently in the anatomy of AI project with LaLanne Chawla is we did an extensive mapping of everything from the natural resources to the labor resources to the data that it takes to make one Amazon echo so that every time you say Alexa what's the weather today you could actually see how much that costs in terms of what's happening in the planet to make that possible and that really taught me something quite profound about how we start thinking about the sort of the way that these systems really work and how some of these costs are actually hidden these particular environmental costs and these labor costs are hidden under very complex logistical and infrastructural systems the second thing that I think we need to think about is the sort of the cost to civic life and how do we sort of really start to bolster issues that are important to us in civic life and we just published a study that took us well over a year where we looked at 13 jurisdictions in the u.s. that are currently covered by consent decrees or other types of judicial orders because of forms of illegal biased or unconstitutional policing what we found is that in many cases that dirty data is being imported directly into predictive policing systems so that means that those systems are actually directing police resources based on illegal data so that's really got to make us think differently about the types of structural issues and our hiss and in this case particularly structural racism that is informing the AI tools of the future and then finally the thing that I think is also really important to start thinking about is governance and I know that's something that on this panel we can have a really good conversation about certainly from my perspective we've been convening leading Public Interest lawyers and legal thinkers in a group called litigating algorithms so we're looking at all of the cases where algorithmic systems are currently in the justice system and looking at the types of legal strategies that are being used to make sure that these systems are actually accountable and this hasn't happened before so it's been an extraordinary research project over over many years so in some I guess I would just say this that I think it's worth thinking about on days like today is that we often tend to think about AI as inevitable it's going to be part of all the systems whether we like it or not it will be threaded through our lives but often I like to sort of ask a different question and say what type of world do you want to live in and how do technologies start to serve that vision rather than drive it so that's one of the big questions I think we should share today and think on yeah I remember I should come back to you as to what you think what your what the vision is that you would like to see I would love to hear that but Tristan you've been thinking you made a comment to me when we were talking earlier about how you think a lot about how these technologies could potentially colonize our spaces and the public squares say more about what you've been thinking about these these kinds of impacts yeah so I think the question that you're raising about governance is you know Marc Andreessen has this phrase that software is eating the world but really we're moving to AI so AI is eating the world so then the question is what's governing this thing as it starts to gobble up parts of the world right so if you take an area of the world that we used to protect like Saturday morning cartoons for kids and then you say let's let AI eat that part of the world so YouTube for kids comes along and it gobbles it up and then it starts you know this is this digital Frankenstein of YouTube for kids starts basically directing children to what they watch 70% of YouTube's traffic now is driven the AI the algorithm so how is it doing I don't know if any of you've been following this but it's not doing such a good job there was videos we could go about how to commit suicide it was being directed to children there's the New Zealand shootings that are just being directed and recommended it systematically tilts YouTube tilts the landscape towards conspiracy theories and radicalization so if you start imagine a spectrum you have the same Walter Cronkite Carl Sagan the side of YouTube and then you have the crazytown side of YouTube this is the spectrum if I'm YouTube and I want you to watch more which direction am I going to send you am I going to send you towards Cronkite or towards crazytown no matter where you start I'm gonna send you that way so it tilts the entire playing field that way so if you start a teen girl in a dieting video she gets recommended anorexia videos is a real example if you start someone on a 911 news video the recommendations are 9/11 conspiracy theories 15 billion recommendations of 9/11 conspiracy theories by Alex Jones were recommended so the scope of how much we have delegated to AI that was just the Saturday morning cartoon section we also sort of talked about public politics then you get elections and you say okay we used to have this thing called the Federal Elections Committee Commission it says there should be an equal price campaign ad you know if it's this much for Hillary Clinton on a Tuesday night 7 p.m. it should be the same price for Donald Trump but then you say let's let Facebook advertising oxygen systems eat up that part of the world and so now you have Facebook basically deciding what the prices are and there's no guarantees for quality so we basically are taking these areas of life that we used to protect we had certain values and we've already just handed over the keys to these systems so then there's this question of so how do you govern it who's to say and how are we gonna do it and I really think the the best quote describes the entire situation that it's the problem statement right now is yo Wilson the father of sociobiology he said the problem of humanity I think he said this 40 years ago the problem of humanity is we have Paleolithic emotions medieval institutions and godlike technology that's it that's what we're chimps with lasers right we we have the power of gods without the wisdom love and compassion of God so then there's this question again or so these medieval institutions part of that quote that's we don't have sophisticated institutions that know anything about how to deal with these things okay so that's out can't really govern it with that perfectly at least we certainly want to upgrade it we have our Paleolithic emotions we've got the 25 year-olds you know what the hoodies wouldn't let them sort of say what's what's gonna happen but that didn't hasn't been working so well and then I want to sell my personal story which is how I got to be doing what I'm doing at home on this stage I was a tech entrepreneur and then I landed at Google through an acquisition and I basically from the inside of Google back in 2013 saw that what was happening with technology was less and less about building things that helped people in more and more this race to capture human attention this race to the bottom of the brainstem who's going to go lower on the brain stem into outrage fear self image hacking identity like variable schedule Ward's dopamine all that stuff and I said we have this enormous responsibility because not just we Google but the entire industry is holding up you know the world attention and we're shaping the flows like a big traffic flow diagram and we have this enormous responsibility get this right in this presentation I made at Google when went viral to about you know 10,000 people and then I became a design ethicist from the inside I'm telling you this for a reason because there's this question of so if you're inside the companies and you're trying to change things from the inside how much power do you have and I say this with no anger or frustration but I tried to change things from the inside at Google for two years and then I I left because I realized fundamentally it was very hard to raise awareness about these issues this is back in 2013 before the election before brexit before Russian hacking all these things so nothing really happened and so in 2016 I left and I went on 60 minutes the television program to talk about brain hacking to create public awareness and media pressure around it and that's when some things started to change them course Cambridge analytic and he's the external events or really what started to drive the industry but I wanted to say this because we're holding on looking at this landscape and we've got these different levers we've got the medieval institutions we've got the inside people trying to change things from the insides as best they can against the incentives but if you're the guy you know inside of YouTube who says hey our recommendation system is systematically steering people towards the crazy stuff someone we work with lo has basically tried to raise awareness inside of YouTube and didn't get very far because YouTube's entire business model is to steer people towards the most engaging stuff and so it's sort of like you wake up 30 years later and you run the NFL and you're the National Football League and you're scientist comes to you and says hey I think that our sport is just basically giving people concussions and our business model is about selling concussions on TV we just slam people's heads together and we sell it against advertising there's not much you can do once you realize that's what a situation is right and I think that's the situation that YouTube's in that's the situation that Facebook's in and so the pressure has to come from the outside and then we can talk about those different levers but we've been looking at you know there's shareholder pressure there's media pressure there's internal employee pressure there's walkouts there's a whole bunch of things that can happen but we have to figure this out so that's how I ended up setting up institution outside to tackle these things yeah but I want to come back to because what we're whenever this topic of yeah as impact in society comes up but I think probably the most written about impact tends to be about work that's been what's been causing a lot of anxiety and I'm just curious I want to dig into that a little bit and then we'll kind of make it conversational there's one view that says we basically jobless future another view that says no no there enough jobs it's just of the quality of the job is what we need to worry about and then there's other views about no no we can scale our way through this I'm just curious Susan and Eric in particular you've been thinking a lot about these work jobs question what you know in a nutshell to say that we can in a panel so we're not gonna go to great depth but what's your view on the work question either so maybe I can just start with a few facts and I think Eric has really done more of his own research on this so I'm kind of reporting other people's research here but Hal Varian is a famous economist we had a conference here recently about the future of work and he made this nice presentation about he called it BOTS and tops so BOTS for the robots and tots are kids and a nice observation that he made is that it's fairly easy to predict how many 40 year olds there will be thirty years from now we kind of know we can predict pretty accurately demographic friends of course we might change immigration policy and in fact after you watch his presentation the first thing you want to do is expand immigration because he's actually you know pointing out that we're going to have across a lot of development countries aging societies and an absence of workers and in fact the the contraction of the labor market he argues is larger quantitative effect than the most aggressive job loss from automation so this is these are kind of back of the envelope calculations I mean governed by data and this is again not my research but I think it's a it's an interesting question to start asking you need to think about these in general equilibrium you can't just look at one side of supply and demand and then if you kind of peel this apart a little bit more micro old people actually require a lot of labor anyone who has brought somebody through hospice or through a long battle with an illness will know this and so if we think about sort of forgetting about who pays board if we think about not having enough jobs roughly for you know sick elderly people you could have sort of one or two human workers per patient productively employed of course this is now kind of unpaid work which is pretty tough work for the people who were doing it and which then ends up transferring people into nursing homes and other forms of care which are incredibly expensive so if we think about you know employing people we can employ people to take care of people in a very productive way now technology can help because of course one reason it's so expensive to have home health aides is you worry about errors and technology can actually dispense drugs it can monitor and surveil it can it can alert you if there is any type of change in your your health state so over time it may be easier actually to have say older people take care of older people for that matter I'm in a safe way and also solve the physical problems now think about young people we can also pretty productively employ human labour teaching young people and anyone who's raised children knows that you can productively employ about one one adult per child and maybe two and so again I think I just think that when you when you look at it that way will there be a positive marginal product for human labor in the future given our demographics of course there will be the question is really then you know how do you pay for it and that could involve for example you know more government reimbursement of home health aides and other types of policies as well as development of technology and and and training the workforce to be appropriate for these types of jobs so I think if you just look at these basic demographics you start to realize that actually this idea that we're all just going to go to the beach and the robots will do everything doesn't seem quite as plausible do you worry a lot about the quality of jobs much more than absence of job I mean diploma what Sousa a lot of it is gonna depend on the timeframe and I think too many people jump to this Hollywood artificial general intelligence scenario where machines can just do right everything and first off even if they could I mean that shouldn't be bad news if we have massive wealth without much need for work we should be able to figure out a way to make that it'd be a good thing it'd be sad if we didn't but that really isn't the challenge that we face right now and I don't think it's a challenge we interface anytime soon we're so far from artificial and Gellin general intelligence that it's and there are so many things that humans are uniquely good at doing what I look around I see so many tasks that need to be done in child care health care community environment in creative work and scientific work in arts and I could go on many other things that only humans can do right now and only who's to be able to do for some time so the challenge is as machines become better and better doing certain types of tasks narrow AI in certain areas how do we redeploy rescale reinvent goods/services tasks to send people in that new direction because it's not necessarily the same people in those two different categories we rescale everybody we can rescale a lot more we are doing right now I think you have to work on both sides of it you can use AI as was mentioned to help with the rescaling and we can be more thoughtful about the kinds of things but also another half of it is entrepreneurs invent things for people to do that use their existing skills and there's a there's a opportunity there as well it's not something that that necessarily professors or policymakers are very good at but one of the great things about a capitalist system is we have lots of people trying out lots of different ways of solving problems and inventing lots of nucleus and servers and and one of the surprising things that the research shows is that we actually have less entrepreneurship less new business formation fewer younger firms now than we did 10 20 and 30 years ago so there's actually been a more of a stagnation and a slowing down on redeploying people and that is just as bad as the lack of rescaling people but if we did more on those sides I think that you know there's as I said earlier there's no shortage of work for humans to do if we were able to redeploy them more effectively and the technology right now is is too often being used simply to automate certain kinds of tasks leaving people without work in those areas and not often enough use to create the new opportunities Kate Kate you've written a lot about these issues of again equity and power and so forth and one of the things you've highlighted a lot and a lot of your work is the fact that part of the challenge in fact you give an example just now is in the underlying data that we used to train these algorithms and its collection and its validity and it's what do we do about that mmm well I mean this is a really hard question because there's as you know a massive race right now to collect all of the forms of data that there can be cognitive biological you name it to feed AI systems that can start to detect large-scale patterns but of course all of those forms of data come with history and they come from a deep social context and I think the attempt to try and erase an 8 that social context from where that data came from and how it was generated is actually going to generate a set of problems for us but there's another question too which is I think a really important one that is sort of hovering over this this wish to make the industry more ethical is that we could actually look to the social sciences where we have a long history of institutional review and ethical review around how you generate and use data so using somebody image or classifying humans or using their words or anything that they've created these things have to go through a review process now right now in the production of AI we don't have any review processes like that that are established at universities and very few and industry although there are a few that are starting to emerge so I think we've actually got some really hard questions to say if we want to make AI more robust and more ethical we have to start thinking about these data collection practices and this is something that we've been doing a lot of work on I know several people in the room are really interested to do more research in this and I think frankly it is going to be one of the biggest problems we hit I mean certainly our predictive policing study really it really shocked me to see that data that was supposed to be completely off the record and this was this was illegal data this was AI corrupt police practices this was like planting evidence on people and these points become data inside a predictive policing system that reorient how surveillance is actually working and where resources are being spent so I've really sort of been thinking very hard about where else we can see these types of I guess you'd call them types of sort of data circles where things are sort of feeding back into systems and what we can do about it well one of the questions that underlies a lot of this and there's been quite a lot of work is you know and actually by some people in this room they linked this issue of bias and fairness with needing to specify fairness can we actually ever specify fairness what does that look like well I mean I'd be interested to see here what other panelists think but certainly I mean this is something that is extremely tough because there's a desire to come up with a quantitative metric for fairness I guess what there isn't one so what we're starting to see is this sort of construction of like tweaking algorithmic systems to create parity now parity is not fairness just because the system works exactly the same on people with lighter skin and darker skin does not mean that we can use we're currently using that system in a fair way so we have to ask I think questions about justice much more than we should be asking these questions about is it fair or does it produce parity so jump in this is it this is I think an opportunity two fronts there's these challenges that the Cape brought up but I want to say also that in most cases the reason that these systems are biased is because they were they learned from biased humans and we the alternative usually isn't a perfect system if the alternative is is relying on humans who judges and hiring and HR officers who are who are biased you know that isn't necessarily an improvement what I see is an opportunity here is that it's often easier to improve the algorithms and to check the algorithms and to remove the bias from them so if we do this right recognizing that there are problems there we have a chance to do better than we have in the past the other thing that's subtler and is also very important your question about do we how do we define fairness is that when we write these systems it forces us to confront what our real goals are what our real values are a lot of that gets blurred when people are making a decision in this link of an eye or in a private hiring thing but when you code it into a system it forces you to think about what is fairness and you and I had a conversation actually like to hear your views of if we can turn this around a bit because you were telling me that they were there what 22 different metrics of whether there's a fun paper out there where somebody tried to actually understand you know different definitions of fantasy who tries to try and code and they came up with about 21 different specifications of fairness and they're all incompatible with each other that's the real challenge and it forces us to as philosophers as citizens decide okay how do we want to balance these different things we can't just sweep out on the rug we have to be explicit about these trade-offs but I also think that they get at the question maybe that's at the heart of this conversation which is you know at some point I imagine we have to be clear about what society we want what outcomes want it to be the ultimate question right and I'm just curious what US panelists think is the future we want in a human sense one thing about this I think that in actually Kate and I got to know each other and trying to think about these issues in in real applications but one of the the challenges is that this is really social science kind of question and so I think it's actually less surprising to social scientists that you can't have your cake and eat it too or that you can't you can't have everything when it comes to fairness this is something that we've thought about for a long time and so of course there's many different approaches to it an economist might think about it in terms of outcomes so when I think about fairness and everything from you know college admissions to employment and so on one thing you care about is incentives and so one notion of fairness might be really good for motivating people to work hard to make everybody feel like if they work hard they have a chance and so if your main idea is to motivate effort and investment then you might focus on one thing well you know in other contexts it might be that you want to take people where they are and treat them fairly either because of legal reasons or it's a some concept of justice so it's really context specific and if you think about even like in a platform event something like facebook or a marketplace it's actually you end up sometimes being unfair you might be unfair to new service providers on Airbnb because they might provide a bad experience to your customers so you you actually have to think harder about just just fairness that's what are you trying to accomplish you're trying to maybe create a platform that works for everybody that's safe and so on so you have these these all these complicated objectives and then to translate those objectives into rules and metrics that guide a system is incredibly hard so even putting aside whatever poor incentives you think firms have even if they're really trying to do the right thing it's it's it's not like you know we have the playbook and and like we can just say okay here this is how you do it right not at all which is why it's got to be a research this is a research endeavor it's a research enterprise it's a program that we need to develop over over a period of time yeah I would agree with that and I would say two things in relation to Eric's point that you know essentially you know we can make code that is somehow sort of fair and less bias than humans but who's inspecting that code who's looking at it that code is being produced often inside very few companies I have an enormous amount of power that you know I'm basically creating proprietary algorithms so you're not really able to order that it doesn't have a sort of a public transparency rule so where its accountability coming and that's the first question the second question is even though yes human institutions are frail and sometimes medieval and we have since the 1500s developed a couple of things that are really handy one of them is called due process we currently have no due process when it comes to how an algorithmic system is deciding whether or not you should be released from jail whether or not you should be getting Medicare in home whether or not you should be getting your child into university so realistically these systems are currently operating outside of due process that's a major problem secondly institutions have all sorts of Appeal mechanisms so even if a judge makes a decision on a day race has a head lunch he's feeling grumpy you can actually appeal that decision you can see how the decision was made there's a text to work from these are not things that we currently have with the algorithmic systems that are already impacting so many sensitive social institutions from healthcare to education to criminal justice so as much as I think it's lovely to say hey algorithms can be less biased than people until we have accountability and due process mechanisms we're actually setting up a trap well let me ask you Kate maybe the panel a question but you know in a lot of these questions we're talking about other principles or due process or any of these mechanisms to deal with these issues these technologies all bring it all pretty and global scale across multiple countries multiple cultures multiple systems how do we square the circles here because some technologies invented here will be applied over there and vice-versa how do you think about the these societal questions in a global context to me that's the core challenge I mean just to say also and the bias and discriminating datasets the dataset that's used to power the entire Internet is called the click and the click is the source of authority in the entire Internet we build up our entire systems off of that and then we in Silicon Valley with the libertarian mindset say that's just giving people what they want and so in 2016 there is this mysterious key word that when Facebook sort of showed people news articles if it had this one key word in it they would always get clicked and it would always get shared and so it just kept giving people what they wanted and that key word was Trump and I say this not saying that from a biased political perspective I'm just saying that's how the algorithm work but from its perspective that's the discriminating police data set but we just hauled back this entire invisible sociological history so now several years later I know from people inside of Facebook that they try to do this stuff to depolarize the system to make it more fair fair in your nervous system so instead of pulling from the bottom of the brainstem let's maybe pull from somewhere else let's try to change polarization but it turns out people aren't clicking on the less polarizing stuff to the point where I heard from a person very senior that they're asking well maybe people just want to be polarized now that's like saying well maybe you know those African Americans who we piped in through those that dataset five generations ago and hauled them through the system so now maybe they really are just you know more criminal right and so the problem is just an Beaudry I wrote about this at the French philosopher you just you keep hauling through these biases through history until you wake up and it's 2019 we think bakes and bacon and eggs go together but that was actually a marketers invention that married two products together to sell better you know propagates through culture now that's norm and we forgot where it came from and we're kind of living in this new reality and then to your point so now you have this global version of it so you can have an appeals process but then you have two billion individual if you take the YouTube case or Facebook case you have two billion program Truman shows two billion individual channels how many engineers at Facebook speak Burmese or there's a genocide going on because of the fake news there how many engineers at YouTube say speak the 22 languages of in India where there's an election coming up in May so now and then how many people that would they have to hire to deal with all the appeals processes all the due process all of that like what's going on is again we've created the godlike technology with with a mathematical and compatibility of all these channels without the kind of loop back around well maybe one question then we'll shift to the audience for questions but maybe one to ruminate on as we think about all these you know clear there's lots of opportunities we've all pointed to the opportunities and we heard a lot about that earlier in the day but you've also pointed all these challenges where does the responsibility lie I mean because you've got the technologists inventing you know the scientists invent new technologies some of them are private companies some of them are labs some of the Makah demyx institutions you've got policy makers you've got regulators you know where does responsibilities lie I think that we did it is I understand the concerns that we've seen in our society but to be fair to the firm's some of these problems are actually pretty hard so I've certainly tackled myself problems in industry where I wanted to do a better job getting away from the clique actually a bunch of my work was about getting getting measures that got away from the clique because even if you're trying to make people happy the clique actually is not a good measure of making them happy but but the problem is that measuring what does make them happy is difficult slow noisy you know if I want to see as a person still with me six months from now I would need to wait six months so actually just the process of operationalizing AI for long term objectives is actually quite tricky so one one thing I talked a lot about in my executive education about AI is that hey this technology no matter what your objective is it's going to make you be more short-term focused why because the technology is something that you want to optimize you want to measure quickly and and so you're gonna need to find short-term proxies and those short-term proxies miss things and so part of I think guiding that the whole process of guiding AI to be more beneficial is to realize that there's more tools than just the technology just what you measure maybe you put rules so if the New York Times just maximized for clicks the entire front page would be full of celebrity stuff within a day or worse but they actually do have rules like certain things can't be entered into the competition for clicks on the front page and the leaders talk to the to the writers about what is consistent with the New York Times and and helps shape the content in those ways so I think ultimately we're going to have to mix methods we're going to have methods of guidance and regulation we're gonna have human inputs oversight the compensate for the parts that the AI systems don't don't fully do and so I guess in terms of the responsibility partly we're here because I think that we feel that there's a collective responsibility that it's not an Yuki no one actor no University no scientist sitting in his lab at 3:00 in the morning trying to you know show up a problem on a tech firm by that no government by themselves we'll get this right first of all we have to bring up the level of the discourse by making sure everybody knows what they're talking about and create conceptual frameworks and then the real work begins of actually trying to figure out the answers well let's go to the audience for questions so please put up your hand if you have a question for the panel hello thank you for thank you for the terrific remarks my name is Mitchell Stevens I'm a sociologist here in the Graduate School of Education at Stanford I want to refer back to Bill Gates's remarks earlier and and push you all a little bit more on where we're going on this question of governance in the 1890s when we were facing massive technological change the United States and northern European countries created the regulatory apparatus that we now inherit at the beginning of the 21st century and during the Cold War when there was another massive wave of technological investment nation state governments were unequivocally in charge of where technological progress as we called it at the time was being directed and it it it's evident from the conversations here that this moment of technological change is not being controlled by any nation-state right nor is any nation-state claiming definitive jurisdiction over it so how do we think about governing a technology when nation-states themselves are agnostic about their ability to control it agree that it's just the responsibility of the nation-states or that it was in those earlier eras there were tremendous inventions in in public school and antitrust and a lot of other things that that this nation in particular but many nations invented to grapple with technological change and later but there are also cultural changes there were labor unions their businesses had different sets of ethics and propagated those and I think that a similar thing today I think the answer to your question has to be all of us get involved I was talking recently with with a technologist developing some AI technologies and and and she was saying you know it's not my responsibility how these things get used I just try to invent the best technologies that was a couple years ago I'd be very surprised if she still said that today because I think partly because of the work at AI now and an H a hi and other organizations and just the the ethos it's become clear that we can't abdicate those responsibilities when we invent these powerful technologies whether it's the fire later we get burned and fire extinguishers or cars wait a minute seatbelts with with the social media we you know we've saw the 2016 election and other hacking attempts sometimes belatedly we come around thinking okay we need to adjust those and if we have an algorithm that's just tuned to optimize clicks in the short run yeah that maximizes engagement maybe get more ads then you realize that even for the firm itself it's not necessarily profit maximizing the firm itself is being hurt and certainly society's being hurt and so each of those different levels is going to look at it and respond to it and you know just to make things a little thorny er my colleague stood on our I'll did some work and Roy and others did some work on the spread of fake news on Twitter and it does indeed spread faster times faster than then truth does but it's not because it's fakes now that people say oh that's fake let me spread that it's because it's so much more engaging it's it's unbelievable it's amazing so but but but here's that here's the unfortunate thing is you know they could identify the bots in the network they they took the bots out and Synthetica said well how fast would have spread if you didn't have the bots just as fast because it was the humans who were really the the bad actors they're deciding to spread this so it even ultimately forces us not just to change our institutions or laws or incentives but to think about our own values and think okay are we doing the right thing how can we spend our time better but they're gonna unfold I mean in some ways you know that that's a way it's a good way to think about it from the point of view of these use and misuse questions but I'm also curious on this responsibility question what you'll think about the responsibilities of things that have an economic impact so I'm thinking about the massive amount retraining that's gonna be needed thus killing the workforce affect the wage effect who is responsible for those again I mean I'll just briefly say it's all those levels so I would love to see the US government and all the governments doing more but you but there are companies that are in we at MIT we have something called the inclusive Innovation Challenge which recognizes rewards organizations that are creating more shared prosperity and there are many companies that are not gonna start naming them because then I'll leave so many off the list and there are nonprofit organizations but I really think it would be a mistake for any of us 2.0 that's that other institutions job to do it and each of us individually can as citizens as voters as CEOs as workers as professors play a role but we have a question there just quickly Ron this idea of like we are all responsible it's to really ask who is that we who is the we who has the power to really have a say here and we're actually talking a pretty limited set of actors and we could even sort of look around this room and say you know who's not present which communities are not represented here and that could often really generate some really interesting insights about who that sort of putative we might be and certainly in terms of who's taking responsibility at the moment we've seen some extraordinary public protests against a lot of issues that have been coming out of technology company that's that's we've seen a tech you know resent technology workers movement we've seen an extraordinary shift to people demanding responsibility so I think both the public sector and the private sector are really gonna have to start thinking a lot harder about what that's gonna look like and Susan actually was the first person I went to mention the word regulation I mean we've heard people like Brad Smith at Microsoft really start to say hey how are we going to regulate these technologies that's a first so I mean I think it's it's really the right moment to start talking about things like a facial recognition that's going to be very very hard to basically regulate just through the private sector or nonprofit sector we actually need to start coming up with much bigger rubrics and some of those are going to have to be international but we've done it before we can look at what happened with nuclear you can look at bodies like the IAEA that actually looked at things like inspections into systems as ways of generating an international consensus to produce pace we're going to need similarly big pitch ideas this time they say that so j-just the firm's I think are perhaps more motivated for regulation than you might think so if you put yourself in the position of a bank and you start using AI you suddenly discover all sorts of things so you might discover that you can just putting people into clusters that there's a cluster and then you look at it and it looks like these people are gambling or they have an alcohol addiction or they have some other thing just looking at expenditure data now they may not have set out to find that and that might have been you know group number 223 but now it's all documented and it's in the records and the regulator three years later might come back and decide that you did something wrong because you didn't act on information that you had and similarly you're going to be writing down in code these risks that you're taking so it actually exposes firms to a whole new set of risks that they really can't understand because five years from now it's going to come get sorted out in litigation whether or not when these documents are subpoenaed you know a jury decides that they acted improperly so I think that really this this this desire for sort of sensible guidance and regulation will will not be controversial among the folks who are struggling with these issues let's get maybe one last question hello I'm marina I'm a journalism fellow at Stanford I wanted to ask about sources of funding for AI and we see that a lot of the sources of funding are concentrated in a handful of companies and a handful of governments and I wanted to ask how that reality clashes we the aspiration that we have to build a more inclusive and more fair and a more independent artificial intelligence somebody want to take that what just well there's not that many people who are free to just speak the truth in all circumstances and so I think the fact that if Google and Facebook are funding the majority of AI research then that presents a lot of huge problems for sure I will send this last question as well that we're originally we're really just lacking the institutions that provide this accountability and I know the people personally who stayed up till 3:00 in the morning the datasets working for nonprofit salaries or if that or fellowships in Mozilla or something trying to calculate you know what these problems are and that's how and then it's through that kind of research that then you try to get a congressman to say hey we got to have a hearing and that's how you get the hearing to happen and you don't want civilians with like no resources being the sole accountability structure for these massive systems so we're really talking about is we need structural accountability systems that we all agree that we would do better off having and that's the question that I think that this institution we're trying to answer completely agree and I just say thank you for that question I mean this issue of power concentration as I said at the outset is one of the biggest issues facing AI I mean we often talk about the big seven in the US and if you include China and that you might be talking about really less than a dozen companies that are really powerful enough to be using AI at scale and of course there are a set of leading universities including this one who have been really important in sort of driving that but that's still an extremely concentrated field and it's really a small group of people who really have their hands on the levers of power in this sort of discussion so when we start to talk about what that looks like geopolitically it actually starts to look very concerning where you start to see power really concentrated in the hands of really depending how you count between three to four nations where everybody else is being relegated to become a client state that's actually something we have to work against we really have to think very carefully about what geopolitical power is going to look like over the next 50 years but it's a great question well I think if nothing else is panels reinforce one thing which is why we need a high because these issues are very multidisciplinary and cover all the disciplines that are going to be included in high but on that note thank you to the panelists you\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "Output Summary: \n",
      "omic law that guarantees the outcomes and the that every benefits I'd love to come back to that at some point is too so what do we do about yes yeah that's that's the key question but Susan you've been thinking about some of these same issues too what's in your mind when you think about impact in society I agree with Eric that we we generally we were going to be able to make sort of more outputs with less inputs and that can potentially be good but the actual process of translating that into well being for all is much more challenging and so one thing that we need to be doing more and better now is to understand why are some people doing badly what are the forces that are are leading to this stagnation those questions still have not been completely unpacked despite a fair bit of empirical research but as we get more and better data and and are really better able to to measure at a finer level what's going on where where exactly have have jobs been been disappearing and why have people not been able to share in this overall growth those will help us identify the problems and I think that even though you know overall the tide may increase we've seen a lot of economic research that shows that if the things start going badly in a particular geography or location they can also spiral down you know people lose their jobs they go less to the hairdresser less to the restaurant and and they have less business and so on so you can certainly have concentrated especially geographically concentrated harm and we just have not done a very good job about figuring out how to fix that and how to smooth those kinds of transitions and that I think takes me to the second thing that I'm thinking about from a positive perspective AI has this great feature it's a general-purpose technology so a lot of the commercial incentives have led to huge advances in R&D in the private sector and we've also seen this great investment within universities and that R&D can be repurposed to solve social p. roblems not that it's going to solve everything but the thing about digitally delivered services is that they have a very low marginal cost of delivery and so if we can actually figure out something that works we can deliver it at scale and so one thing that I'm really excited about is trying to develop the a body of research that can help social impact firms find it easier to get started collaborations between universities and nonprofits or governments to really help bring these services to the people who need them and the nice thing about digital services also is this this in AI systems generally is this culture of incremental innovation so generally a tech product is not good when it first launches instead you make it better and better and better you learn you adapt the one-size-fits-all isn't great but once it adapts to the person and really understands them it can actually really become effective and so I think there's a whole set of social problems where the conventional wisdom is that we don't have a solution but we just haven't tried this next set of technologies and so the university we have a whole university full of engineers and students of all disciplines who who would love to and as part of their education actually apprentice in in solving social problems and doing something impactful instead of just going to target ads in their internship and so I think we have a great opportunity to harness and leverage that huge desire of people to learn and of researchers to study to and direct those towards the problems that might be caused by AI and and generally automation into this digitization and then the the third point and I hope we'll come back to this in the discussion further but is when I spent a lot of time with tech companies and you know we can talk a lot about their perverse incentives and how profits might lead them to do things that can that aren't good for consumers or society but there's actually a lot of cases where the firm's really are missio. n driven and it's actually just hard it's hard because they're inventing the science they're inventing the business processes they're inventing the AI they're trying to do good but it they just weren't trained to anticipate all of the the consequences and so you know it's it's really incumbent upon us and this is really a core mission of high is to you know help provide that leadership one one company by themselves especially small companies couldn't possibly be expected to have the expertise to anticipate you know all the different things that their technologies all the consequences that could follow from their technologies and so by convening industry and government and academia I think there's the possibility to really get all the people in the room to start asking the right questions but that's gonna be an ongoing research process it's not like I could lay out now and say here are the rules and if you just do this you're AI will be good no instead the technology is going to progress and the policy research is going to have to progress right alongside it in an ongoing way so it's really a process rather than a single final goal and I know we're going to come back to these work impacts well that's clearly a big topic of most people's minds but is the two resident economists on our panel Susan and Eric are you optimistic about the impact on economic growth and productivity yes in time I think that one of the disappointments has been that actually proactivity has been pretty dismal in the past few years and that's actually been a little bit of a surprise and disappointment to me in thinking more about it and it really gets some of the things we're doing here at high which is that the technologies have been invented if you look at their capabilities you have to be incredibly optimistic this is one of the great general purpose technology is comparable to the steam engine or electricity but if you look back those technologies didn't instantly boost growth they took dec. ades because new kinds of factories had to be invented new work rules whole new institutions had to be invented and that's what we need to do now as well and sadly that takes a lot longer than then sometimes inventing the technologies they're Greeson you just to add to that I think you know it can be very confusing it too to follow this space because on the one hand you see the a is you know playing go and you know the robots climbing the walls and doing backflips and so you sort of feel like it's like all solved but then when you look at the even the very most advanced tech firms and and the most advanced practical implementations they're still actually relatively primitive they're using very simple AI and you know there are some amazing successes but across the board even like personalization and recommendations or are still sort of so-so and those have been the ones that have gotten in some sense the most commercial incentive to improve so I think part of the thing is that we are just very early it takes a lot of time and one reason it takes a lot of time is that you have to actually figure out how to measure success if you're gonna climb up a mountain you know you need to have a good signal of which way to go and that's one reason that it actually takes a long time this isn't a breakthrough in the lab that just immediately is applicable everywhere the part about putting it in a practice is interdisciplinary and our discipline with an affirm and interdisciplinary within science but we're working on it okay Kate you've been thinking a lot about these many of these issues related to equity and justice and well first of all tell everybody what yeah now is by the way so the be delighted to thank you James so I mean I've essentially been researching the social implications of machine learning and artificial intelligence and large-scale data for well over a decade now and about three years ago with Meredith Whittaker who's also here today and we decided to found basica. servers and and one of the surprising things that the research shows is that we actually have less entrepreneurship less new business formation fewer younger firms now than we did 10 20 and 30 years ago so there's actually been a more of a stagnation and a slowing down on redeploying people and that is just as bad as the lack of rescaling people but if we did more on those sides I think that you know there's as I said earlier there's no shortage of work for humans to do if we were able to redeploy them more effectively and the technology right now is is too often being used simply to automate certain kinds of tasks leaving people without work in those areas and not often enough use to create the new opportunities Kate Kate you've written a lot about these issues of again equity and power and so forth and one of the things you've highlighted a lot and a lot of your work is the fact that part of the challenge in fact you give an example just now is in the underlying data that we used to train these algorithms and its collection and its validity and it's what do we do about that mmm well I mean this is a really hard question because there's as you know a massive race right now to collect all of the forms of data that there can be cognitive biological you name it to feed AI systems that can start to detect large-scale patterns but of course all of those forms of data come with history and they come from a deep social context and I think the attempt to try and erase an 8 that social context from where that data came from and how it was generated is actually going to generate a set of problems for us but there's another question too which is I think a really important one that is sort of hovering over this this wish to make the industry more ethical is that we could actually look to the social sciences where we have a long history of institutional review and ethical review around how you generate and use data so using somebody image or classifying humans or using their w. ords or anything that they've created these things have to go through a review process now right now in the production of AI we don't have any review processes like that that are established at universities and very few and industry although there are a few that are starting to emerge so I think we've actually got some really hard questions to say if we want to make AI more robust and more ethical we have to start thinking about these data collection practices and this is something that we've been doing a lot of work on I know several people in the room are really interested to do more research in this and I think frankly it is going to be one of the biggest problems we hit I mean certainly our predictive policing study really it really shocked me to see that data that was supposed to be completely off the record and this was this was illegal data this was AI corrupt police practices this was like planting evidence on people and these points become data inside a predictive policing system that reorient how surveillance is actually working and where resources are being spent so I've really sort of been thinking very hard about where else we can see these types of I guess you'd call them types of sort of data circles where things are sort of feeding back into systems and what we can do about it well one of the questions that underlies a lot of this and there's been quite a lot of work is you know and actually by some people in this room they linked this issue of bias and fairness with needing to specify fairness can we actually ever specify fairness what does that look like well I mean I'd be interested to see here what other panelists think but certainly I mean this is something that is extremely tough because there's a desire to come up with a quantitative metric for fairness I guess what there isn't one so what we're starting to see is this sort of construction of like tweaking algorithmic systems to create parity now parity is not fairness just because the system . \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \")\n",
    "print(result)\n",
    "print() \n",
    "print() \n",
    "print() \n",
    "print() \n",
    "print() \n",
    "print() \n",
    "print() \n",
    "print() \n",
    "print() \n",
    "print() \n",
    "\n",
    "print(\"=============================================================================================================\")\n",
    "print() \n",
    "print() \n",
    "print() \n",
    "print() \n",
    "print() \n",
    "print(\" \")\n",
    "print(\"Output Summary: \")\n",
    "print(final_summary)\n",
    "print() \n",
    "print() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Thank You </h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0747f93ff6db21b2db2bf35ad4858dd0825b9c21797c41b4cc32097944ab3f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
